{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072565f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7db2617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_8316\\337482542.py:50: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  route_info = review.find(text=\"Route\")\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_8316\\337482542.py:54: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  seat = review.find(text=\"Seat Type\")\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_8316\\337482542.py:58: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  flown_date = review.find(text=\"Date Flown\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Scraping page 32...\n",
      "Scraping page 33...\n",
      "Scraping page 34...\n",
      "Scraping page 35...\n",
      "Scraping page 36...\n",
      "Data scraping completed.\n",
      "Review titles collected: 3600\n",
      "Review content collected: 3600\n",
      "Star ratings collected: 3600\n",
      "Review dates collected: 3600\n",
      "Countries collected: 3600\n",
      "Routes collected: 3600\n",
      "Seat types collected: 3600\n",
      "Dates flown collected: 3600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize lists to store extracted data\n",
    "reviews_title = []\n",
    "reviews_content = []\n",
    "stars = []\n",
    "review_date = []\n",
    "country = []\n",
    "route = []\n",
    "seat_type = []\n",
    "date_flown = []\n",
    "\n",
    "# Loop over pages to scrape\n",
    "for i in range(1, 37):\n",
    "    print(f\"Scraping page {i}...\")\n",
    "    \n",
    "    # Fetch the page content\n",
    "    page = requests.get(f\"https://www.airlinequality.com/airline-reviews/british-airways/page/{i}/?sortby=post_date%3ADesc&pagesize=100\")\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    # Find all reviews on the page\n",
    "    reviews = soup.find_all(\"article\", {\"itemprop\": \"review\"})\n",
    "\n",
    "    # Process each review block\n",
    "    for review in reviews:\n",
    "        # Extract review title\n",
    "        title = review.find(\"h2\", class_=\"text_header\")\n",
    "        reviews_title.append(title.get_text(strip=True) if title else \"N/A\")\n",
    "\n",
    "        # Extract review content\n",
    "        content = review.find(\"div\", class_=\"text_content\")\n",
    "        reviews_content.append(content.get_text(strip=True) if content else \"N/A\")\n",
    "\n",
    "        # Extract star ratings\n",
    "        rating = review.find(\"div\", class_=\"rating-10\")\n",
    "        stars.append(rating.span.get_text(strip=True) if rating and rating.span else \"N/A\")\n",
    "\n",
    "        # Extract review dates\n",
    "        date = review.find(\"time\")\n",
    "        review_date.append(date.get_text(strip=True) if date else \"N/A\")\n",
    "\n",
    "        # Extract reviewer countries\n",
    "        reviewer_country = review.find(\"h3\")\n",
    "        country.append(reviewer_country.span.next_sibling.strip(\" ()\") if reviewer_country and reviewer_country.span else \"N/A\")\n",
    "\n",
    "        # Extract flight route\n",
    "        route_info = review.find(text=\"Route\")\n",
    "        route.append(route_info.find_next(\"td\").get_text(strip=True) if route_info else \"N/A\")\n",
    "\n",
    "        # Extract seat type\n",
    "        seat = review.find(text=\"Seat Type\")\n",
    "        seat_type.append(seat.find_next(\"td\").get_text(strip=True) if seat else \"N/A\")\n",
    "\n",
    "        # Extract date flown\n",
    "        flown_date = review.find(text=\"Date Flown\")\n",
    "        date_flown.append(flown_date.find_next(\"td\").get_text(strip=True) if flown_date else \"N/A\")\n",
    "\n",
    "    # Pause to avoid overloading the server\n",
    "    time.sleep(2)\n",
    "\n",
    "# Display summary of data collected\n",
    "print(\"Data scraping completed.\")\n",
    "print(f\"Review titles collected: {len(reviews_title)}\")\n",
    "print(f\"Review content collected: {len(reviews_content)}\")\n",
    "print(f\"Star ratings collected: {len(stars)}\")\n",
    "print(f\"Review dates collected: {len(review_date)}\")\n",
    "print(f\"Countries collected: {len(country)}\")\n",
    "print(f\"Routes collected: {len(route)}\")\n",
    "print(f\"Seat types collected: {len(seat_type)}\")\n",
    "print(f\"Dates flown collected: {len(date_flown)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0baffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to 'british_airways_reviews.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Create the DataFrame without immediate type casting\n",
    "df = pd.DataFrame({\n",
    "    \"review_title\": reviews_title,\n",
    "    \"review_content\": reviews_content,\n",
    "    \"stars\": stars,\n",
    "    \"review_date\": review_date,\n",
    "    \"country\": country,\n",
    "    \"route\": route,\n",
    "    \"seat_type\": seat_type,\n",
    "    \"date_flown\": date_flown\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"british_airways_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Data successfully saved to 'british_airways_reviews.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4809fbd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3600 entries, 0 to 3599\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   review_title    3600 non-null   object        \n",
      " 1   review_content  3600 non-null   object        \n",
      " 2   stars           3597 non-null   float64       \n",
      " 3   review_date     3600 non-null   datetime64[ns]\n",
      " 4   country         3598 non-null   object        \n",
      " 5   route           3110 non-null   object        \n",
      " 6   seat_type       3598 non-null   object        \n",
      " 7   date_flown      3108 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(6)\n",
      "memory usage: 225.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c7c89d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_title              object\n",
      "review_content            object\n",
      "stars                    float64\n",
      "review_date       datetime64[ns]\n",
      "country                   object\n",
      "route                     object\n",
      "seat_type                 object\n",
      "date_flown                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the types of the DataFrame to verify\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c118f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
